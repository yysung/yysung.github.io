[{"authors":["yoo-yeon-sung"],"categories":null,"content":"Hi, I\u0026rsquo;m Yoo Yeon (\u0026ldquo;You-yawn\u0026rdquo;)! I am a fifth-year Ph.D. candidate at the College of Information at University of Maryland, College Park. I am fortunate to be advised by Jordan Boyd-Graber and Naeemul Hassan. I got a M.S. degree in Industrial Management Engineering from Korea university, and B.S. degree in English Literature and Language from Chung-Ang University. I was a visiting researcher at KAIST AI Graduate school, advised by Jaegul Choo.\nResearch Focus My research is centered on Human-Centered NLP and Responsible AI, with an aim to develop AI systems that align closely with human needs. Ultimately, I strive to create AI models that not only achieve high accuracy but also foster positive social impact by enhancing reliability and fostering supportive, human-complementary interactions. My specific interests are:\nBenchmark Dataset Creation: Develop datasets that evaluate language models based on human-centered standards. Robustness Metrics: Design metrics that assess LLM robustness through the lens of human capabilities. Human-AI Interaction Testing: Evaluate human-AI interactive systems that support and complement human users effectively. Broad Research Areas 1. Human-AI Alignment Developing and testing human-AI interactive systems that are designed to effectively support and complement human users. 2. Human-Centered LLM Evaluation Creating human-grounded frameworks and benchmarks to assess the robustness and reliability of AI in diverse applications. 3. Robust Benchmark Dataset Construction Building adversarial datasets that enable fair and accurate evaluation of AI, emphasizing real-world applicability and human-centered validation. 4. Combating Misinformation Leveraging large language models (LLMs) to detect, mitigate, and prevent the spread of misinformation in digital environments. Research Vision I am particularly interested in exploring how advancements in LLMs shape the evolving dynamics of human-computer interaction, especially within the context of the ongoing information crisis. My approach emphasizes tackling these challenges from a human-centered perspective, ensuring AI is developed to genuinely benefit people.\n","date":1729814400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1729814400,"objectID":"80f3ba9f8df1eced15b4ff7ca4119456","permalink":"/author/yoo-yeon-sung-%EC%84%B1%EC%9C%A0%EC%97%B0/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yoo-yeon-sung-%EC%84%B1%EC%9C%A0%EC%97%B0/","section":"authors","summary":"Hi, I\u0026rsquo;m Yoo Yeon (\u0026ldquo;You-yawn\u0026rdquo;)! I am a fifth-year Ph.D. candidate at the College of Information at University of Maryland, College Park. I am fortunate to be advised by Jordan Boyd-Graber and Naeemul Hassan.","tags":null,"title":"Yoo Yeon Sung (성유연)","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"42bc04c138a3c5b43479eff9fa12bf11","permalink":"/home-unused/slider/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/slider/","section":"home-unused","summary":"","tags":null,"title":"","type":"home-unused"},{"authors":null,"categories":null,"content":"The Best Way to Create the Website You Want from Markdown (or Jupyter/RStudio)\nBuild Anything with Widgets\nStar\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ff3af16109a08648bdce10d3973de99c","permalink":"/home-unused/hero/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/hero/","section":"home-unused","summary":"The Best Way to Create the Website You Want from Markdown (or Jupyter/RStudio)\nBuild Anything with Widgets\nStar","tags":null,"title":"Academic","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4a7e3501655fed0a4b0ce814e15ff2c9","permalink":"/home-unused/skills/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/skills/","section":"home-unused","summary":"","tags":null,"title":"Skills","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d6682c06ff2f3dd0fc28f7e2c0702d07","permalink":"/home-unused/experience/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/experience/","section":"home-unused","summary":"","tags":null,"title":"Experience","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9e909a8894fd21a2eff4b3e43238d81e","permalink":"/home-unused/accomplishments/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/accomplishments/","section":"home-unused","summary":"","tags":null,"title":"Accomplish\u0026shy;ments","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0e643989bdefe366f2b5fddf949a36b6","permalink":"/home-unused/posts/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/posts/","section":"home-unused","summary":"","tags":null,"title":"Recent Posts","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"89201c04ad04664a30c3fb9ba7b170aa","permalink":"/home-unused/projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/projects/","section":"home-unused","summary":"","tags":null,"title":"Projects","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b3f45f4a1c65dae9e5e30f53b9f83edd","permalink":"/home-unused/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/people/","section":"home-unused","summary":"","tags":null,"title":"Meet the Team","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d927b251d3da15a737d1f66fb88d4504","permalink":"/home-unused/talks/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/talks/","section":"home-unused","summary":"","tags":null,"title":"Recent \u0026 Upcoming Talks","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"28f54f6e819207239a6024bbaa9d78de","permalink":"/home-unused/featured/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/featured/","section":"home-unused","summary":"","tags":null,"title":"Featured Publications","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"657179738bed56748434d6ae76e8a647","permalink":"/home-unused/tags/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/tags/","section":"home-unused","summary":"","tags":null,"title":"Popular Topics","type":"home-unused"},{"authors":["Tasnim Kabir","Yoo Yeon Sung (성유연)","Saptarashmi Bandyopadhyay","Hao Zou","Abhranil Chandra","and Jordan Lee Boyd-Graber"],"categories":null,"content":"","date":1729814400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729814400,"objectID":"e332be1f0c6c6099bcbf743a9a4982ce","permalink":"/publication/you-make-me-feel-like-a-natural-question-training-qa-systems-on-transformed-trivia-questions/","publishdate":"2024-10-25T00:00:00Z","relpermalink":"/publication/you-make-me-feel-like-a-natural-question-training-qa-systems-on-transformed-trivia-questions/","section":"publication","summary":"Training question-answering QA and information retrieval systems for web queries require large, expensive datasets that are difficult to annotate and time-consuming to gather. Moreover, while natural datasets of information-seeking questions are often prone to ambiguity or ill-formed, there are troves of freely available, carefully crafted question datasets for many languages. Thus, we automatically generate shorter, information-seeking questions, resembling web queries in the style of the Natural Questions (NQ) dataset from longer trivia data. Training a QA system on these transformed questions is a viable strategy for alternating to more expensive training setups showing the F1 score difference of less than six points and contrasting the final systems.","tags":null,"title":"You Make me Feel like a Natural Question: Training QA Systems on Transformed Trivia Questions","type":"publication"},{"authors":["Yoo Yeon Sung (성유연)","Maharshi Gor","Eve Fleisig","Ishani Mondal","and Jordan Boyd-Graber"],"categories":null,"content":"","date":1719273600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719273600,"objectID":"88dc38d84f0603ade683ff308524bb99","permalink":"/publication/advscore-a-metric-for-the-evaluation-and-creation-of-adversarial-benchmarks/","publishdate":"2024-06-25T00:00:00Z","relpermalink":"/publication/advscore-a-metric-for-the-evaluation-and-creation-of-adversarial-benchmarks/","section":"publication","summary":"Adversarial datasets should ensure AI robustness that matches human performance. However, as models evolve, datasets can become obsolete. Thus, adversarial datasets should be periodically updated based on their degradation in adversarialness. Given the lack of a standardized metric for measuring adversarialness, we propose AdvScore, a human-grounded evaluation metric. AdvScore assesses a dataset's true adversarialness by capturing models' and humans' varying abilities, while also identifying poor examples. AdvScore then motivates a new dataset creation pipeline for realistic and high-quality adversarial samples, enabling us to collect an adversarial question answering (QA) dataset, AdvQA. We apply AdvScore using 9,347 human responses and ten language model predictions to track the models' improvement over five years (from 2020 to 2024). AdvScore assesses whether adversarial datasets remain suitable for model evaluation, measures model improvements, and provides guidance for better alignment with human capabilities.","tags":null,"title":"Is your benchmark truly adversarial? AdvScore: Evaluating Human-Grounded Adversarialness","type":"publication"},{"authors":["Yoo Yeon Sung (성유연)","Jordan Boyd-Graber","and Naeemul Hassan"],"categories":null,"content":"","date":1674864000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674864000,"objectID":"c29fbec4c00454566165a1fbc08199fc","permalink":"/publication/not-all-fake-news-is-written-a-dataset-and-analysis-of-misleading-video-headlines/","publishdate":"2023-01-05T00:00:00Z","relpermalink":"/publication/not-all-fake-news-is-written-a-dataset-and-analysis-of-misleading-video-headlines/","section":"publication","summary":"Polarization and the marketplace for impressions have conspired to make navigating information online difficult for users, and while there has been a significant effort to detect false or misleading text, multimodal datasets have received considerably less attention. To complement existing resources, we present multimodal Video Misleading Headline (VMH), a dataset that consists of videos and whether annotators believe the headline is representative of the video's contents. After collecting and annotating this dataset, we analyze multimodal baselines for detecting misleading headlines. Our annotation process also focuses on why annotators view a video as misleading, allowing us to better understand the interplay of annotators' background and the content of the videos.","tags":null,"title":"Not all Fake News is Written: A Dataset and Analysis of Misleading Video Headlines","type":"publication"},{"authors":["Yoo Yeon Sung (성유연)","Ishani Mondal","and Jordan Boyd-Graber"],"categories":null,"content":"","date":1674172800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674172800,"objectID":"dafed33703b955b148a5e8f45d8266b5","permalink":"/publication/how-the-advent-of-ubiquitous-large-language-models-both-stymie-and-turbocharge-dynamic-adversarial-question-generation/","publishdate":"2023-01-20T00:00:00Z","relpermalink":"/publication/how-the-advent-of-ubiquitous-large-language-models-both-stymie-and-turbocharge-dynamic-adversarial-question-generation/","section":"publication","summary":"Dynamic adversarial question generation, where humans write examples to stump a model, aims to create examples that are realistic and informative. However, the advent of large language models (LLMs) has been a double-edged sword for human authors: more people are interested in seeing and pushing the limits of these models, but because the models are so much stronger an opponent, they are harder to defeat. To understand how these models impact adversarial question writing process, we enrich the writing guidance with LLMs and retrieval models for the authors to reason why their questions are not adversarial. While authors could create interesting, challenging adversarial questions, they sometimes resort to tricks that result in poor questions that are ambiguous, subjective, or confusing not just to a computer but also to humans. To address these issues, we propose new metrics and incentives for eliciting good, challenging questions and present a new dataset of adversarially authored questions.","tags":null,"title":"How the Advent of Ubiquitous Large Language Models both Stymie and Turbocharge Dynamic Adversarial Question Generation","type":"publication"},{"authors":["Yoo Yeon Sung and Seoung Bum Kim"],"categories":null,"content":"","date":1580169600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580169600,"objectID":"b93bb640d9f7d59daa9d5005769a8633","permalink":"/publication/topical-keyphrase-extraction-with-hierarchical-semantic-networks/","publishdate":"2020-01-05T00:00:00Z","relpermalink":"/publication/topical-keyphrase-extraction-with-hierarchical-semantic-networks/","section":"publication","summary":"Topical keyphrase extraction is used to summarize large collections of text documents. However, traditional methods cannot properly reflect the intrinsic semantics and relationships of keyphrases because they rely on a simple term-frequency-based process. Consequently, these methods are not effective in obtaining significant contextual knowledge. To resolve this, we propose a topical keyphrase extraction method based on a hierarchical semantic network and multiple centrality network measures that together reflect the hierarchical semantics of keyphrases. We conduct experiments on real data to examine the practicality of the proposed method and to compare its performance with that of existing topical keyphrase extraction methods. The results confirm that the proposed method outperforms state-of-the-art topical keyphrase extraction methods in terms of the representativeness of the selected keyphrases for each topic. The proposed method can effectively reflect intrinsic keyphrase semantics and interrelationships.","tags":null,"title":"Topical Keyphrase Extraction with Hierarchical Semantic Networks","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1da304e9ea1b167ac9baed030c02b693","permalink":"/talk/nottalk/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talk/nottalk/","section":"talk","summary":"","tags":null,"title":"Recent \u0026 Upcoming Talks","type":"talk"}]